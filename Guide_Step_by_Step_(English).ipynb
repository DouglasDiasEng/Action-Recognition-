{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPkZni1lFvcX0NMx5x13/Ex",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/DouglasDiasEng/Action-Recognition-/blob/main/Guide_Step_by_Step_(English).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Installing the Libraries\n",
        "\n",
        "To get started, we install two essntial libraries: **OpenCV** and **TensorFlow Hub**, which will be used to process the videos and load the pre-trained action recognition model.\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "mTvP6s-8nkBR"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "WudiiY0Tnfzm"
      },
      "outputs": [],
      "source": [
        "!pip install -q opencv-python tensorflow_hub"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Importing the Libraries\n",
        "\n",
        "In this section, we import all the necessary libraries for video processing, model loading, temporary file management, and displaying results in the notebook. The print statement shows the current version of TensorFlow installed in the environment, ensuring it is compatible with the model bing loaded.\n",
        "\n"
      ],
      "metadata": {
        "id": "K8Rsgyw4oAXz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import tensorflow_hub as hub\n",
        "from google.colab.patches import cv2_imshow\n",
        "import re\n",
        "import os\n",
        "import tempfile\n",
        "import ssl\n",
        "import cv2\n",
        "import numpy as np\n",
        "from urllib import request\n",
        "from IPython.display import HTML\n",
        "from base64 import b64encode\n",
        "\n",
        "print(\"TensorFlow version: \", tf.__version__)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "CqfEkroRopGJ",
        "outputId": "40e03dba-b991-426b-ded6-5ed9c3d76095"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "TensorFlow version:  2.19.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Carregando os Rótulos do Kinetics-400\n",
        "\n",
        "O modelo I3D utiliza a lista de ações do dataset **Kinetics-400**, que contém 400 classes diferentes.  \n",
        "Neste trecho, fazemos o download dessa lista diretamente do repositório oficial e a carregamos em uma lista Python.\n"
      ],
      "metadata": {
        "id": "eko0trGMtt-h"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "url_classes = 'https://raw.githubusercontent.com/deepmind/kinetics-i3d/master/data/label_map.txt'\n",
        "with request.urlopen(url_classes) as file:\n",
        "  label = [row.decode('utf-8').strip() for row in file.readlines()]\n",
        "\n",
        "print(\"Total de classes: \", len(label))\n",
        "print(\"Algumas classes: \", label[:10])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "0oCahowytxst",
        "outputId": "368dda24-7b05-49df-ab7a-4fad955a0641"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total de classes:  400\n",
            "Algumas classes:  ['abseiling', 'air drumming', 'answering questions', 'applauding', 'applying cream', 'archery', 'arm wrestling', 'arranging flowers', 'assembling computer', 'auctioning']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Configuração Inicial para Download dos Vídeos\n",
        "\n",
        "Antes de processar qualquer vídeo, precisamos definir onde eles serão buscados e onde serão armazenados temporariamente no ambiente.  \n",
        "Neste trecho, criamos essas configurações e definimos uma função para listar vídeos conhecidos."
      ],
      "metadata": {
        "id": "wJmjN1oc-Qqk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "root_folder = 'https://www.crcv.ucf.edu/THUMOS14/UCF101/UCF101/'\n",
        "context = ssl._create_unverified_context()\n",
        "cache_videos = tempfile.mkdtemp()\n",
        "print(\"Pasta temporária para vídeos:\", cache_videos)\n",
        "\n",
        "def list_videos():\n",
        "  known_videos = [\n",
        "    'v_PizzaTossing_g23_c03.avi',\n",
        "    'v_ApplyEyeMakeup_g01_c01.avi',\n",
        "    'v_Archery_g01_c01.avi'\n",
        "]\n",
        "  return known_videos\n",
        "\n",
        "print(\"Lista de vídeos conhecidos:\", list_videos())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "Ua4zYT0J-UCL",
        "outputId": "5cc63d79-2882-4e77-cbbe-fa15640a1a12"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Pasta temporária para vídeos: /tmp/tmpy8j137dx\n",
            "Lista de vídeos conhecidos: ['v_PizzaTossing_g23_c03.avi', 'v_ApplyEyeMakeup_g01_c01.avi', 'v_Archery_g01_c01.avi']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Função para Baixar e Armazenar o Vídeo Localmente\n",
        "\n",
        "Esta função é responsável por fazer o download de um vídeo da internet e salvar em uma pasta temporária.  \n",
        "Caso o vídeo já tenha sido baixado antes, ela evita o download repetido."
      ],
      "metadata": {
        "id": "cYzXWfcZai5D"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def save_video(video_name):\n",
        "  cache_path = os.path.join(cache_videos, video_name)\n",
        "  if not os.path.exists(cache_path):\n",
        "    url_path = request.urljoin(root_folder, video_name)\n",
        "    print(\"Baixando de:\", url_path)\n",
        "    data = request.urlopen(url_path, context=context).read()\n",
        "    with open(cache_path, 'wb') as f:\n",
        "      f.write(data)\n",
        "    print(\"Video salvo em:\", cache_path)\n",
        "  else:\n",
        "    print(\"Vídeo já existe em cache:\", cache_path)\n",
        "  return cache_path\n",
        "\n",
        "video_name = 'v_PizzaTossing_g23_c03.avi'\n",
        "video_path = save_video(video_name)\n",
        "\n",
        "print(\"Caminho final do vídeo:\", video_path)\n",
        "print(\"Arquivo existe?\", os.path.exists(video_path))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "IJOWno7AcJFX",
        "outputId": "48fb7735-ec09-4aa3-d6c7-547c5b9908b9"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Baixando de: https://www.crcv.ucf.edu/THUMOS14/UCF101/UCF101/v_PizzaTossing_g23_c03.avi\n",
            "Video salvo em: /tmp/tmpy8j137dx/v_PizzaTossing_g23_c03.avi\n",
            "Caminho final do vídeo: /tmp/tmpy8j137dx/v_PizzaTossing_g23_c03.avi\n",
            "Arquivo existe? True\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Função para Carregar o Vídeo com OpenCV\n",
        "\n",
        "Esta função lê um vídeo salvo em disco, extrai os frames, redimensiona para o tamanho esperado pelo modelo e converte tudo em um array NumPy normalizado entre 0 e 1."
      ],
      "metadata": {
        "id": "g98tfPOH_oMM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def load_video(path, visualize=False):\n",
        "  cap = cv2.VideoCapture(path)\n",
        "  frames = []\n",
        "\n",
        "  if not cap.isOpened():\n",
        "    print(\"Não foi possível abrir o vídeo:\", path)\n",
        "    return np.array([])\n",
        "\n",
        "  while True:\n",
        "    connected, frame = cap.read()\n",
        "    if not connected:\n",
        "      break\n",
        "\n",
        "    frame = cv2.resize(frame, (224, 224))\n",
        "    frames.append(frame)\n",
        "\n",
        "  cap.release()\n",
        "\n",
        "  if not frames:\n",
        "    print(\"Nenhum frame foi lido do vídeo.\")\n",
        "    return np.array([])\n",
        "\n",
        "  frames = np.array(frames, dtype=np.float32)\n",
        "\n",
        "  if visualize and frames.size > 0:\n",
        "    cv2_imshow(frames[0].astype(np.uint8))\n",
        "\n",
        "  return frames / 255.0\n",
        "\n",
        "video_frames = load_video(video_path, visualize=False)\n",
        "print(\"Formato do array de frames:\", video_frames.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "l8FjF0tr_nn9",
        "outputId": "2df205cc-e406-45ec-a3c0-63b489a08e47"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Formato do array de frames: (148, 224, 224, 3)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Conversão e Visualização do Vídeo no Notebook\n",
        "\n",
        "Este trecho verifica se o vídeo foi carregado corretamente e, caso positivo, converte o arquivo `.avi` para `.mp4` e exibe o vídeo dentro do notebook."
      ],
      "metadata": {
        "id": "D6f13vx_onyJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "if video_frames.size > 0:\n",
        "  output_mp4_path = \"/content/output.mp4\"\n",
        "  !ffmpeg -y -i \"$video_path\" \"$output_mp4_path\"\n",
        "\n",
        "  if os.path.exists(output_mp4_path):\n",
        "    mp4 = open(output_mp4_path, 'rb').read()\n",
        "    data_url = 'data:video/mp4;base64,' +b64encode(mp4).decode()\n",
        "\n",
        "    display(HTML(f\"\"\"\n",
        "      <video width=\"400\" controls>\n",
        "        <source src=\"{data_url}\" type=\"video/mp4\">\n",
        "      </video>\n",
        "      \"\"\"))\n",
        "  else:\n",
        "    print(\"Falha ao criar o arquivo mp4\")"
      ],
      "metadata": {
        "id": "2PHGSXPionTW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Carregando o Modelo I3D do TensorFlow Hub\n",
        "\n",
        "Nesta etapa, carregamos o modelo **I3D (Inflated 3D ConvNet)** pré-treinado no dataset **Kinetics-400** diretamente do **TensorFlow Hub**.  \n",
        "Esse modelo é o responsável por fazer o reconhecimento de ações a partir dos frames do vídeo."
      ],
      "metadata": {
        "id": "YDd_gQ1N3Nvf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Carregando modelo do TensorFlow Hub (pode demorar um pouco)...\")\n",
        "model = hub.load('https://tfhub.dev/deepmind/i3d-kinetics-400/1').signatures['default']\n",
        "print(\"Modelo carregado com sucesso!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "HK6vvDWM3UWe",
        "outputId": "bb4d4c93-6a5d-4814-f52b-d3e0da726aa4"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Carregando modelo do TensorFlow Hub (pode demorar um pouco)...\n",
            "Modelo carregado com sucesso!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Preparando o Vídeo para o Modelo e Realizando a Inferência\n",
        "\n",
        "Depois de carregar o vídeo e o modelo, precisamos ajustar o formato dos frames para o padrão esperado pelo I3D e então realizar a previsão da ação presente no vídeo.\n"
      ],
      "metadata": {
        "id": "U9AZjXBi4_lP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "if video_frames.size == 0:\n",
        "  raise ValueError(\"O vídeo não possui frames. Verifique o caminho ou o download.\")\n",
        "\n",
        "test_video = tf.constant(video_frames, dtype=tf.float32)[tf.newaxis, ...]\n",
        "print(\"Shape do video para o modelo:\", test_video.shape)\n",
        "\n",
        "outputs = model(test_video)\n",
        "logits = outputs['default'][0]\n",
        "probabilities = tf.nn.softmax(logits).numpy()\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "GzJP-OFc5eIW",
        "outputId": "bbf69308-eb52-4d92-eb69-5c2ef2457936"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape do video para o modelo: (1, 148, 224, 224, 3)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Analisando os Resultados da Inferência\n",
        "\n",
        "Agora que temos as probabilidades previstas para cada uma das 400 classes do modelo, precisamos identificar qual ação o modelo acredita estar sendo realizada no vídeo."
      ],
      "metadata": {
        "id": "2Whi6iB7oyhu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "top_class = np.argmax(probabilities)\n",
        "print(\"Classe mais prováve (indice):\", top_class)\n",
        "print(\"Ação mais provável::\", label[top_class])\n",
        "print(\"Confiança: {:.2f}%\".format(probabilities[top_class]*100))\n",
        "print(\"\\nTop 5 ações principais:\")\n",
        "top_idx = np.argsort(probabilities)[::-1][:5]\n",
        "for i in top_idx:\n",
        "  print(f\"{label[i]:35}: {probabilities[i]*100:5.2f} %\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "3prBdhWEo-SN",
        "outputId": "fbd76ea7-84d0-4b04-f43a-9caeab3b8b9c"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Classe mais prováve (indice): 188\n",
            "Ação mais provável:: making pizza\n",
            "Confiança: 36.47%\n",
            "\n",
            "Top 5 ações principais:\n",
            "making pizza                       : 36.47 %\n",
            "punching bag                       : 28.43 %\n",
            "catching or throwing frisbee       :  6.93 %\n",
            "pumping fist                       :  5.17 %\n",
            "washing dishes                     :  4.70 %\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "tGhBSGxdtBsm"
      }
    }
  ]
}