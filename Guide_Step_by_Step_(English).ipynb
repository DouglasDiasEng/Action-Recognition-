{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOQRw8Sya1yfF/gcz0NXOs5",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/DouglasDiasEng/Action-Recognition-/blob/main/Guide_Step_by_Step_(English).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Installing the Libraries\n",
        "\n",
        "To get started, we install two essntial libraries: **OpenCV** and **TensorFlow Hub**, which will be used to process the videos and load the pre-trained action recognition model.\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "mTvP6s-8nkBR"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "WudiiY0Tnfzm"
      },
      "outputs": [],
      "source": [
        "!pip install -q opencv-python tensorflow_hub"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Importing the Libraries\n",
        "\n",
        "In this section, we import all the necessary libraries for video processing, model loading, temporary file management, and displaying results in the notebook. The print statement shows the current version of TensorFlow installed in the environment, ensuring it is compatible with the model bing loaded.\n",
        "\n"
      ],
      "metadata": {
        "id": "K8Rsgyw4oAXz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import tensorflow_hub as hub\n",
        "from google.colab.patches import cv2_imshow\n",
        "import re\n",
        "import os\n",
        "import tempfile\n",
        "import ssl\n",
        "import cv2\n",
        "import numpy as np\n",
        "from urllib import request\n",
        "from IPython.display import HTML\n",
        "from base64 import b64encode\n",
        "\n",
        "print(\"TensorFlow version: \", tf.__version__)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "CqfEkroRopGJ",
        "outputId": "40e07a8c-70c2-446e-e4e3-f29ebd758e62"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "TensorFlow version:  2.19.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Loading the Kinetics-400 Lables\n",
        "\n",
        "The I3D model uses the action list from the **Kinetics-400** dataset, which contains 400 different classes.\n",
        "In this section, we download this list directly from the official repository and load it into a Python list.\n",
        "\n"
      ],
      "metadata": {
        "id": "eko0trGMtt-h"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "url_classes = 'https://raw.githubusercontent.com/deepmind/kinetics-i3d/master/data/label_map.txt'\n",
        "with request.urlopen(url_classes) as file:\n",
        "  label = [row.decode('utf-8').strip() for row in file.readlines()]\n",
        "\n",
        "print(\"Total number of classes: \", len(label))\n",
        "print(\"Some classes: \", label[:10])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "0oCahowytxst",
        "outputId": "5e851268-b062-498f-b4f7-7ddb57db4972"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total number of classes:  400\n",
            "Some classes:  ['abseiling', 'air drumming', 'answering questions', 'applauding', 'applying cream', 'archery', 'arm wrestling', 'arranging flowers', 'assembling computer', 'auctioning']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Initial Setup for Downloading Videos\n",
        "\n",
        "Before processing any video, we need to define where they will be fetched from and where they will by temporarily stored in the environmnt.\n",
        "In this section, we create these configurations and define a function to list know videos."
      ],
      "metadata": {
        "id": "wJmjN1oc-Qqk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "root_folder = 'https://www.crcv.ucf.edu/THUMOS14/UCF101/UCF101/'\n",
        "context = ssl._create_unverified_context()\n",
        "cache_videos = tempfile.mkdtemp()\n",
        "print(\"Temporary folder for videos:\", cache_videos)\n",
        "\n",
        "def list_videos():\n",
        "  known_videos = [\n",
        "    'v_PizzaTossing_g23_c03.avi',\n",
        "    'v_ApplyEyeMakeup_g01_c01.avi',\n",
        "    'v_Archery_g01_c01.avi'\n",
        "]\n",
        "  return known_videos\n",
        "\n",
        "print(\"List of known videos\", list_videos())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "Ua4zYT0J-UCL",
        "outputId": "ac0d21ef-ec65-4161-9109-119fd657c6c5"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Temporary folder for videos: /tmp/tmp1923iquq\n",
            "List of known videos ['v_PizzaTossing_g23_c03.avi', 'v_ApplyEyeMakeup_g01_c01.avi', 'v_Archery_g01_c01.avi']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Function to Download and Store the Video Locally\n",
        "\n",
        "This function is responsable for downloading a video from the internet and saving it in a temporary folder.\n",
        "If the video has already been downloaded beforee, it prevents repeated downloads.\n"
      ],
      "metadata": {
        "id": "cYzXWfcZai5D"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def save_video(video_name):\n",
        "  cache_path = os.path.join(cache_videos, video_name)\n",
        "  if not os.path.exists(cache_path):\n",
        "    url_path = request.urljoin(root_folder, video_name)\n",
        "    print(\"Downloading from:\", url_path)\n",
        "    data = request.urlopen(url_path, context=context).read()\n",
        "    with open(cache_path, 'wb') as f:\n",
        "      f.write(data)\n",
        "    print(\"Video saved in:\", cache_path)\n",
        "  else:\n",
        "    print(\"The video already exists in cache:\", cache_path)\n",
        "  return cache_path\n",
        "\n",
        "video_name = 'v_PizzaTossing_g23_c03.avi'\n",
        "video_path = save_video(video_name)\n",
        "\n",
        "print(\"final path of the video:\", video_path)\n",
        "print(\"Does the file exist?\", os.path.exists(video_path))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "IJOWno7AcJFX",
        "outputId": "c593aaa6-b53a-4931-e704-cd99c9feee51"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading from: https://www.crcv.ucf.edu/THUMOS14/UCF101/UCF101/v_PizzaTossing_g23_c03.avi\n",
            "Video saved in: /tmp/tmp1923iquq/v_PizzaTossing_g23_c03.avi\n",
            "final path of the video: /tmp/tmp1923iquq/v_PizzaTossing_g23_c03.avi\n",
            "Does the file exist? True\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Function to Load the Video with OpenCV\n",
        "\n",
        "This function reads a video saved on disk, extracts the frames, resizes them to the siz expcted by the model, and converts everything into a NumPy array normalized between 0 and 1."
      ],
      "metadata": {
        "id": "g98tfPOH_oMM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def load_video(path, visualize=False):\n",
        "  cap = cv2.VideoCapture(path)\n",
        "  frames = []\n",
        "\n",
        "  if not cap.isOpened():\n",
        "    print(\"Failed to open the video\", path)\n",
        "    return np.array([])\n",
        "\n",
        "  while True:\n",
        "    connected, frame = cap.read()\n",
        "    if not connected:\n",
        "      break\n",
        "\n",
        "    frame = cv2.resize(frame, (224, 224))\n",
        "    frames.append(frame)\n",
        "\n",
        "  cap.release()\n",
        "\n",
        "  if not frames:\n",
        "    print(\"No frames were read from the video.\")\n",
        "    return np.array([])\n",
        "\n",
        "  frames = np.array(frames, dtype=np.float32)\n",
        "\n",
        "  if visualize and frames.size > 0:\n",
        "    cv2_imshow(frames[0].astype(np.uint8))\n",
        "\n",
        "  return frames / 255.0\n",
        "\n",
        "video_frames = load_video(video_path, visualize=False)\n",
        "print(\"Frame array shape\", video_frames.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "l8FjF0tr_nn9",
        "outputId": "75b43390-6fc8-4a42-af1b-ba2aa1a927cd"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Frame array shape (148, 224, 224, 3)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Video Conversion and Visualization in the Notebook\n",
        "\n",
        "This section checks whether the video was loaded correctly and, if so, converts the `.avi` file to `.mp4` and displays the video inside the notebook.\n",
        "\n"
      ],
      "metadata": {
        "id": "D6f13vx_onyJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "if video_frames.size > 0:\n",
        "  output_mp4_path = \"/content/output.mp4\"\n",
        "  !ffmpeg -y -i \"$video_path\" \"$output_mp4_path\"\n",
        "\n",
        "  if os.path.exists(output_mp4_path):\n",
        "    mp4 = open(output_mp4_path, 'rb').read()\n",
        "    data_url = 'data:video/mp4;base64,' +b64encode(mp4).decode()\n",
        "\n",
        "    display(HTML(f\"\"\"\n",
        "      <video width=\"400\" controls>\n",
        "        <source src=\"{data_url}\" type=\"video/mp4\">\n",
        "      </video>\n",
        "      \"\"\"))\n",
        "  else:\n",
        "    print(\"Failed to creat the mp4 file\")"
      ],
      "metadata": {
        "id": "2PHGSXPionTW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Loading the I3D Model from TensorFlow Hub\n",
        "\n",
        "In this step, we load the **I3D(inflated 3D ConvNet)** model pre-trained on the **Kinetics-400** dataset directly from **TensorFlow Hub**.\n",
        "This model is responsible for performing action recognition based on the video frames.\n",
        "\n"
      ],
      "metadata": {
        "id": "YDd_gQ1N3Nvf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Loading model from TensorFlow Hub (this may take a moment)...\")\n",
        "model = hub.load('https://tfhub.dev/deepmind/i3d-kinetics-400/1').signatures['default']\n",
        "print(\"Model loaded successfuly!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "HK6vvDWM3UWe",
        "outputId": "0fabec32-9fbd-4f55-b6c0-98023dae3887"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading model from TensorFlow Hub (this may take a moment)...\n",
            "Model loaded successfuly!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Preparing the Video for the Model and Runnig Inference\n",
        "\n",
        "After loading the video and the model, we need to adjust the frame format to match the input expected by I3D and then perform the action prediction on the video.\n"
      ],
      "metadata": {
        "id": "U9AZjXBi4_lP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "if video_frames.size == 0:\n",
        "  raise ValueError(\"The video contains no frames. Check the path or the download.\")\n",
        "\n",
        "test_video = tf.constant(video_frames, dtype=tf.float32)[tf.newaxis, ...]\n",
        "print(\"Video shape for the model:\", test_video.shape)\n",
        "\n",
        "outputs = model(test_video)\n",
        "logits = outputs['default'][0]\n",
        "probabilities = tf.nn.softmax(logits).numpy()\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "GzJP-OFc5eIW",
        "outputId": "83c3690e-f282-4df0-83cc-fb5bc0b0eb46"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Video shape for the model: (1, 148, 224, 224, 3)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Analyzing the Inference Results\n",
        "\n",
        "Now that we have the predicted probabilities for each of the 400 classes in the model, we need to determine which action the model believes is being performed in the video."
      ],
      "metadata": {
        "id": "2Whi6iB7oyhu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "top_class = np.argmax(probabilities)\n",
        "print(\"Most probable class (index):\", top_class)\n",
        "print(\"Most likely action:\", label[top_class])\n",
        "print(\"Confidence: {:.2f}%\".format(probabilities[top_class] * 100))\n",
        "print(\"\\nTop 5 actions:\")\n",
        "top_idx = np.argsort(probabilities)[::-1][:5]\n",
        "for i in top_idx:\n",
        "    print(f\"{label[i]:35}: {probabilities[i] * 100:5.2f} %\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "3prBdhWEo-SN",
        "outputId": "ea12abfd-ded7-476a-d554-e2a1e615ec72"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Most probable class (index): 188\n",
            "Most likely action: making pizza\n",
            "Confidence: 36.47%\n",
            "\n",
            "Top 5 actions:\n",
            "making pizza                       : 36.47 %\n",
            "punching bag                       : 28.43 %\n",
            "catching or throwing frisbee       :  6.93 %\n",
            "pumping fist                       :  5.17 %\n",
            "washing dishes                     :  4.70 %\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "tGhBSGxdtBsm"
      }
    }
  ]
}